{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加入数据\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#from tensorflow.example.tutorials.mnist import input_data\n",
    "\n",
    "#构建参数\n",
    "learning_rate = 0.01 #学习率\n",
    "training_epochs = 20 # 训练的轮数\n",
    "batch_size = 256 # 每次训练的数据多少\n",
    "display_step = 1 # 每隔多少轮显示一次训练结果\n",
    "\n",
    "#表示从测试集选择10张图片去验证\n",
    "example_to_show = 10\n",
    "\n",
    "#网络参数\n",
    "n_hidden_1 = 256 #第一个隐藏层神经元的个数，也就是特征值个数\n",
    "n_hidden_2 = 128 #第二个隐藏层神经元的个数，也就是特征值个数\n",
    "n_input = 784    #输入数据的特征值个数： 28×28=784\n",
    "\n",
    "#定义输入数据\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "\n",
    "#初始化每一层的权重和偏置\n",
    "weights = {\n",
    "    'encoder_h1':tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'encoder_h2':tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'decoder_h1':tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),\n",
    "    'decoder_h2':tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n",
    "}\n",
    "biases = {\n",
    "    'encoder_b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'encoder_b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'decoder_b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'decoder_b2':tf.Variable(tf.random_normal([n_input])),  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'init' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-90aba355a3b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# 3训练数据及评估模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mtotal_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m#开始训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'init' is not defined"
     ]
    }
   ],
   "source": [
    "#定义压缩函数\n",
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmod actication #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
    "                                  biases['encoder_b1']))\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
    "                                  biases['encoder_b2']))\n",
    "    return layer_2\n",
    "\n",
    "#定义解压函数\n",
    "def decoder(x):\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
    "                                  biases['decoder_b1']))\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
    "                                  biases['decoder_b2']))\n",
    "    return layer_2\n",
    "#构建模型\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "##损失函数用最小二乘法\n",
    "\n",
    "#得出预测值\n",
    "y_pred = decoder_op\n",
    "#得出真实值, 即输入值\n",
    "y_true = X\n",
    "\n",
    "#定义损失函数和优化器\n",
    "cost =  tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# 3训练数据及评估模型\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    #开始训练\n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            #Run optimization op (backprop) and cost op (to get loss value)\n",
    "            c = sess.run([optimizer, cost], feed_dict = {X: batch_xs})\n",
    "            # 每一轮, 打印出一次损失值\n",
    "            if epoch % display_step == 0:\n",
    "                print (\"Epoch:\", '%04d' % (epoch + 1), \"cost=\", \"{:.9f}\".format(c))\n",
    "    print (\"Optimization Finished!\")\n",
    "    \n",
    "    #对测试集应用训练好的自动编码网络\n",
    "    encode_decode = sess.run(y_pred, feed_dict = {X: mnist.test.images[:examples_to_show]})\n",
    "    f, a = plt.subplots(2, 10, figsize = (10, 2))\n",
    "    for i in range(examples_to_show):\n",
    "        a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))#测试集\n",
    "        a[1][i].imshow(np.reshape(encode_decode[i], (28, 28))) #重建结果\n",
    "    f.show()\n",
    "    plt.draw()\n",
    "    plt.waitforbuttonpress()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
